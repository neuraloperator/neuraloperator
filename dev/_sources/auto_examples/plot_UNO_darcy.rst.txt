
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_UNO_darcy.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_UNO_darcy.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_UNO_darcy.py:


U-NO on Darcy-Flow
==================

In this example, we demonstrate how to train a U-shaped Neural Operator on 
the small Darcy-Flow example we ship with the package

.. GENERATED FROM PYTHON SOURCE LINES 11-25

.. code-block:: Python



    import torch
    import matplotlib.pyplot as plt
    import sys
    from neuralop.models import TFNO, UNO
    from neuralop import Trainer
    from neuralop.data.datasets import load_darcy_flow_small
    from neuralop.utils import count_model_params
    from neuralop import LpLoss, H1Loss

    device = 'cpu'









.. GENERATED FROM PYTHON SOURCE LINES 26-27

Loading the Darcy Flow dataset

.. GENERATED FROM PYTHON SOURCE LINES 27-45

.. code-block:: Python

    train_loader, test_loaders, data_processor = load_darcy_flow_small(
            n_train=1000, batch_size=32, 
            test_resolutions=[16, 32], n_tests=[100, 50],
            test_batch_sizes=[32, 32],
    )



    model = UNO(3,1, hidden_channels=64, projection_channels=64,uno_out_channels = [32,64,64,64,32], \
                uno_n_modes= [[16,16],[8,8],[8,8],[8,8],[16,16]], uno_scalings=  [[1.0,1.0],[0.5,0.5],[1,1],[2,2],[1,1]],\
                horizontal_skips_map = None, n_layers = 5, domain_padding = 0.2)
    model = model.to(device)

    n_params = count_model_params(model)
    print(f'\nOur model has {n_params} parameters.')
    sys.stdout.flush()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading test db for resolution 16 with 100 samples 
    Loading test db for resolution 32 with 50 samples 

    Our model has 2665921 parameters.




.. GENERATED FROM PYTHON SOURCE LINES 46-47

Create the optimizer

.. GENERATED FROM PYTHON SOURCE LINES 47-53

.. code-block:: Python

    optimizer = torch.optim.Adam(model.parameters(), 
                                    lr=8e-3, 
                                    weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)









.. GENERATED FROM PYTHON SOURCE LINES 54-55

Creating the losses

.. GENERATED FROM PYTHON SOURCE LINES 55-62

.. code-block:: Python

    l2loss = LpLoss(d=2, p=2)
    h1loss = H1Loss(d=2)

    train_loss = h1loss
    eval_losses={'h1': h1loss, 'l2': l2loss}









.. GENERATED FROM PYTHON SOURCE LINES 63-74

.. code-block:: Python



    print('\n### MODEL ###\n', model)
    print('\n### OPTIMIZER ###\n', optimizer)
    print('\n### SCHEDULER ###\n', scheduler)
    print('\n### LOSSES ###')
    print(f'\n * Train: {train_loss}')
    print(f'\n * Test: {eval_losses}')
    sys.stdout.flush()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    ### MODEL ###
     UNO(
      (domain_padding): DomainPadding()
      (lifting): MLP(
        (fcs): ModuleList(
          (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))
          (1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
        )
      )
      (fno_blocks): ModuleList(
        (0): FNOBlocks(
          (convs): SpectralConv(
            (weight): ModuleList(
              (0): ComplexDenseTensor(shape=torch.Size([64, 32, 16, 9]), rank=None)
            )
          )
          (fno_skips): ModuleList(
            (0): Flattened1dConv(
              (conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
          )
        )
        (1): FNOBlocks(
          (convs): SpectralConv(
            (weight): ModuleList(
              (0): ComplexDenseTensor(shape=torch.Size([32, 64, 8, 5]), rank=None)
            )
          )
          (fno_skips): ModuleList(
            (0): Flattened1dConv(
              (conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
            )
          )
        )
        (2): FNOBlocks(
          (convs): SpectralConv(
            (weight): ModuleList(
              (0): ComplexDenseTensor(shape=torch.Size([64, 64, 8, 5]), rank=None)
            )
          )
          (fno_skips): ModuleList(
            (0): Flattened1dConv(
              (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
            )
          )
        )
        (3): FNOBlocks(
          (convs): SpectralConv(
            (weight): ModuleList(
              (0): ComplexDenseTensor(shape=torch.Size([128, 64, 8, 5]), rank=None)
            )
          )
          (fno_skips): ModuleList(
            (0): Flattened1dConv(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            )
          )
        )
        (4): FNOBlocks(
          (convs): SpectralConv(
            (weight): ModuleList(
              (0): ComplexDenseTensor(shape=torch.Size([96, 32, 16, 9]), rank=None)
            )
          )
          (fno_skips): ModuleList(
            (0): Flattened1dConv(
              (conv): Conv1d(96, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
          )
        )
      )
      (horizontal_skips): ModuleDict(
        (0): Flattened1dConv(
          (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
        )
        (1): Flattened1dConv(
          (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (projection): MLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
        )
      )
    )

    ### OPTIMIZER ###
     Adam (
    Parameter Group 0
        amsgrad: False
        betas: (0.9, 0.999)
        capturable: False
        differentiable: False
        eps: 1e-08
        foreach: None
        fused: None
        initial_lr: 0.008
        lr: 0.008
        maximize: False
        weight_decay: 0.0001
    )

    ### SCHEDULER ###
     <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7fb2d07aa760>

    ### LOSSES ###

     * Train: <neuralop.losses.data_losses.H1Loss object at 0x7fb2cb5013a0>

     * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7fb2cb5013a0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7fb2cb501460>}




.. GENERATED FROM PYTHON SOURCE LINES 75-76

Create the trainer

.. GENERATED FROM PYTHON SOURCE LINES 76-86

.. code-block:: Python

    trainer = Trainer(model=model,
                       n_epochs=20,
                      device=device,
                      data_processor=data_processor,
                      wandb_log=False,
                      log_test_interval=3,
                      use_distributed=False,
                      verbose=True)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    self.override_load_to_device=False
    self.overrides_loss=False




.. GENERATED FROM PYTHON SOURCE LINES 87-88

Actually train the model on our small Darcy-Flow dataset

.. GENERATED FROM PYTHON SOURCE LINES 88-98

.. code-block:: Python


    trainer.train(train_loader=train_loader,
                  test_loaders=test_loaders,
                  optimizer=optimizer,
                  scheduler=scheduler, 
                  regularizer=False, 
                  training_loss=train_loss,
                  eval_losses=eval_losses)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Training on 32 samples
    Testing on [50, 50] samples         on resolutions [16, 32].
    Raw outputs of shape torch.Size([32, 1, 16, 16])
    [0] time=5.80, avg_loss=0.6082, train_err=19.0048, 16_h1=0.6863, 16_l2=0.4684, 32_h1=0.6360, 32_l2=0.3697
    [3] time=5.76, avg_loss=0.2760, train_err=8.6252, 16_h1=0.6692, 16_l2=0.4669, 32_h1=0.6254, 32_l2=0.4401
    [6] time=5.82, avg_loss=0.2407, train_err=7.5216, 16_h1=0.6603, 16_l2=0.4707, 32_h1=0.6125, 32_l2=0.4675
    [9] time=5.76, avg_loss=0.2179, train_err=6.8093, 16_h1=0.6603, 16_l2=0.4702, 32_h1=0.6039, 32_l2=0.4774
    [12] time=5.75, avg_loss=0.2214, train_err=6.9175, 16_h1=0.6333, 16_l2=0.4543, 32_h1=0.5890, 32_l2=0.4760
    [15] time=5.85, avg_loss=0.1984, train_err=6.1995, 16_h1=0.7044, 16_l2=0.4766, 32_h1=0.6018, 32_l2=0.4678
    [18] time=5.78, avg_loss=0.1793, train_err=5.6029, 16_h1=0.6042, 16_l2=0.4415, 32_h1=0.5802, 32_l2=0.4736

    {'16_h1': 0.6042024230957032, '16_l2': 0.4415410804748535, '32_h1': 0.5802475547790528, '32_l2': 0.47362098693847654}



.. GENERATED FROM PYTHON SOURCE LINES 99-109

Plot the prediction, and compare with the ground-truth 
Note that we trained on a very small resolution for
a very small number of epochs
In practice, we would train at larger resolution, on many more samples.

However, for practicity, we created a minimal example that
i) fits in just a few Mb of memory
ii) can be trained quickly on CPU

In practice we would train a Neural Operator on one or multiple GPUs

.. GENERATED FROM PYTHON SOURCE LINES 109-147

.. code-block:: Python


    test_samples = test_loaders[32].dataset

    fig = plt.figure(figsize=(7, 7))
    for index in range(3):
        data = test_samples[index]
        data = data_processor.preprocess(data, batched=False)
        # Input x
        x = data['x']
        # Ground-truth
        y = data['y']
        # Model prediction
        out = model(x.unsqueeze(0).to(device)).cpu()

        ax = fig.add_subplot(3, 3, index*3 + 1)
        ax.imshow(x[0], cmap='gray')
        if index == 0: 
            ax.set_title('Input x')
        plt.xticks([], [])
        plt.yticks([], [])

        ax = fig.add_subplot(3, 3, index*3 + 2)
        ax.imshow(y.squeeze())
        if index == 0: 
            ax.set_title('Ground-truth y')
        plt.xticks([], [])
        plt.yticks([], [])

        ax = fig.add_subplot(3, 3, index*3 + 3)
        ax.imshow(out.squeeze().detach().numpy())
        if index == 0: 
            ax.set_title('Model prediction')
        plt.xticks([], [])
        plt.yticks([], [])

    fig.suptitle('Inputs, ground-truth output and prediction.', y=0.98)
    plt.tight_layout()
    fig.show()



.. image-sg:: /auto_examples/images/sphx_glr_plot_UNO_darcy_001.png
   :alt: Inputs, ground-truth output and prediction., Input x, Ground-truth y, Model prediction
   :srcset: /auto_examples/images/sphx_glr_plot_UNO_darcy_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 58.656 seconds)


.. _sphx_glr_download_auto_examples_plot_UNO_darcy.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_UNO_darcy.ipynb <plot_UNO_darcy.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_UNO_darcy.py <plot_UNO_darcy.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
