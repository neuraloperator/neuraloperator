{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training a SFNO on the spherical Shallow Water equations\n\nIn this example, we demonstrate how to use the small Spherical Shallow Water Equations example we ship with the package\nto train a Spherical Fourier-Neural Operator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport matplotlib.pyplot as plt\nimport sys\nfrom neuralop.models import SFNO\nfrom neuralop import Trainer\nfrom neuralop.datasets import load_spherical_swe\nfrom neuralop.utils import count_params\nfrom neuralop import LpLoss, H1Loss\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the Navier-Stokes dataset in 128x128 resolution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_loader, test_loaders = load_spherical_swe(n_train=200, batch_size=4, train_resolution=(32, 64),\n                                                test_resolutions=[(32, 64), (64, 128)], n_tests=[50, 50], test_batch_sizes=[10, 10],)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a tensorized FNO model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = SFNO(n_modes=(32, 32), in_channels=3, out_channels=3, hidden_channels=32, projection_channels=64, factorization='dense')\nmodel = model.to(device)\n\nn_params = count_params(model)\nprint(f'\\nOur model has {n_params} parameters.')\nsys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the optimizer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), \n                                lr=8e-4, \n                                weight_decay=0.0)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the losses\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "l2loss = LpLoss(d=2, p=2, reduce_dims=(0,1))\n# h1loss = H1Loss(d=2, reduce_dims=(0,1))\n\ntrain_loss = l2loss\neval_losses={'l2': l2loss} #'h1': h1loss,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('\\n### MODEL ###\\n', model)\nprint('\\n### OPTIMIZER ###\\n', optimizer)\nprint('\\n### SCHEDULER ###\\n', scheduler)\nprint('\\n### LOSSES ###')\nprint(f'\\n * Train: {train_loss}')\nprint(f'\\n * Test: {eval_losses}')\nsys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the trainer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model, n_epochs=20,\n                  device=device,\n                  mg_patching_levels=0,\n                  wandb_log=False,\n                  log_test_interval=3,\n                  use_distributed=False,\n                  verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actually train the model on our small Darcy-Flow dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader, test_loaders,\n              None,\n              model, \n              optimizer,\n              scheduler, \n              regularizer=False, \n              training_loss=train_loss,\n              eval_losses=eval_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the prediction, and compare with the ground-truth \nNote that we trained on a very small resolution for\na very small number of epochs\nIn practice, we would train at larger resolution, on many more samples.\n\nHowever, for practicity, we created a minimal example that\ni) fits in just a few Mb of memory\nii) can be trained quickly on CPU\n\nIn practice we would train a Neural Operator on one or multiple GPUs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(7, 7))\nfor index, resolution in enumerate([(32, 64), (64, 128)]):\n    test_samples = test_loaders[resolution].dataset\n    data = test_samples[0]\n    # Input x\n    x = data['x']\n    # Ground-truth\n    y = data['y'][0, ...].numpy()\n    # Model prediction\n    out = model(x.unsqueeze(0)).squeeze()[0, ...].detach().numpy()\n    x = x[0, ...].detach().numpy()\n\n    ax = fig.add_subplot(2, 3, index*3 + 1)\n    ax.imshow(x)\n    ax.set_title(f'Input x {resolution}')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\n    ax = fig.add_subplot(2, 3, index*3 + 2)\n    ax.imshow(y)\n    ax.set_title('Ground-truth y')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\n    ax = fig.add_subplot(2, 3, index*3 + 3)\n    ax.imshow(out)\n    ax.set_title('Model prediction')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\nfig.suptitle('Inputs, ground-truth output and prediction.', y=0.98)\nplt.tight_layout()\nfig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}